{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 4: Colab Experiment**"
      ],
      "metadata": {
        "id": "4ZlU8khsZjZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Introduction\n",
        "In this exercise, we load the Breast cancer wisconsin dataset for classification.\n",
        "\n",
        "The approach combines multiple machine learning techniques to optimize model performance using hyperparameter tuning, cross-validation, and ensemble methods. First, data is preprocessed using a pipeline with StandardScaler to ensure consistent feature scaling. Models such as Logistic Regression, Support Vector Machine (SVM), and Decision Tree are constructed. We employ GridSearchCV for hyperparameter tuning, using a grid of parameters for Logistic Regression and SVM, such as C, kernel, and gamma"
      ],
      "metadata": {
        "id": "E3LRo3ehZo2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Methods"
      ],
      "metadata": {
        "id": "Sn2Bcr9sZofG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X4dRDQZqqiet"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import zero_one_loss\n",
        "from sklearn.decomposition import PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dependent and independent variables.\n",
        "data = load_breast_cancer()\n",
        "Y = data.target\n",
        "X = data.data\n"
      ],
      "metadata": {
        "id": "ArV6oId2qjCh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CV folds\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, random_state=0, shuffle=True)\n",
        "kfold_indices = {}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "  kfold_indices[f\"fold_{i}\"] = {'train': train_index, 'test': test_index}"
      ],
      "metadata": {
        "id": "_kY6lUBXL0TX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter grids for each classifier\n",
        "param_grid_logreg = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'classifier__penalty': ['l1', 'l2'],\n",
        "    'classifier__solver': ['liblinear', 'saga'],\n",
        "    'classifier__max_iter': [10000]  # Higher iteration counts for better convergence\n",
        "}\n",
        "\n",
        "param_grid_svm = {\n",
        "    'classifier__C': [0.1, 1, 10, 100, 1000, 5000, 10000],  # Regularization strength\n",
        "    'classifier__kernel': ['linear', 'rbf', 'poly'],  # Different kernels to test\n",
        "    'classifier__gamma': ['scale', 'auto', 0.01, 0.1, 0.5, 1],  # Kernel coefficient\n",
        "    'classifier__degree': [2, 3, 4, 5, 6],  # Polynomial degree, only used for 'poly' kernel\n",
        "    'classifier__class_weight': [None, 'balanced'],  # Use balanced class weights\n",
        "    'classifier__coef0': [0.0, 0.1, 0.3, 0.5, 0.8, 1.0],  # Coef0 for poly and sigmoid kernels\n",
        "}\n",
        "\n",
        "param_grid_tree = {\n",
        "    'classifier__max_depth': [None, 5, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4],\n",
        "    'classifier__criterion': ['gini', 'entropy']\n",
        "}"
      ],
      "metadata": {
        "id": "Lsstw6qAJvRy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Error_rate = {'logreg': [], 'svm': [], 'decision_tree': []}"
      ],
      "metadata": {
        "id": "d0TdAg8tjbaN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models and apply them to the test set\n",
        "\n",
        "for fold_id in range(num_folds):\n",
        "  X_train = X[kfold_indices[f\"fold_{fold_id}\"]['train']]\n",
        "  Y_train = Y[kfold_indices[f\"fold_{fold_id}\"]['train']]\n",
        "  X_test = X[kfold_indices[f\"fold_{fold_id}\"]['test']]\n",
        "  Y_test = Y[kfold_indices[f\"fold_{fold_id}\"]['test']]\n",
        "\n",
        "  # Logistic regression\n",
        "  ######################## TODO #####################################\n",
        "  pipe_logreg = Pipeline([\n",
        "      ('scaler', StandardScaler()),  # Step 1: Standardize features\n",
        "      ('pca', PCA(n_components=0.95)),  # Step 2: PCA to reduce dimensionality\n",
        "      ('classifier', LogisticRegression(random_state=0, max_iter=1000))  # Step 3: Logistic Regression\n",
        "  ])\n",
        "  clf_logreg = GridSearchCV(Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(random_state=100))  # Increase max_iter\n",
        "  ]), param_grid_logreg, cv=5)\n",
        "  clf_logreg.fit(X_train, Y_train)\n",
        "\n",
        "  # Make predictions and compute error rate\n",
        "  Y_pred = clf_logreg.predict(X_test)\n",
        "  error = zero_one_loss(Y_test, Y_pred)\n",
        "\n",
        "  Error_rate['logreg'].append(error)\n",
        "  #####################################################################"
      ],
      "metadata": {
        "id": "UsTfhZNxL0V1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold_id in range(num_folds):\n",
        "  # Prepare train and test data for this fold\n",
        "  X_train = X[kfold_indices[f\"fold_{fold_id}\"]['train']]\n",
        "  Y_train = Y[kfold_indices[f\"fold_{fold_id}\"]['train']]\n",
        "  X_test = X[kfold_indices[f\"fold_{fold_id}\"]['test']]\n",
        "  Y_test = Y[kfold_indices[f\"fold_{fold_id}\"]['test']]\n",
        "\n",
        "  # SVM\n",
        "  #####################################################################\n",
        "  # Create the pipeline for SVM with StandardScaler\n",
        "  pipe_svm = Pipeline([\n",
        "      ('scaler', StandardScaler()),  # Standardize features\n",
        "      ('classifier', SVC(random_state=0))  # SVM classifier\n",
        "  ])\n",
        "\n",
        "  # Use GridSearchCV for hyperparameter tuning\n",
        "  clf_svm = GridSearchCV(pipe_svm, param_grid_svm, cv=5, scoring='accuracy')\n",
        "\n",
        "  # Fit the model using the best parameters found by GridSearchCV\n",
        "  clf_svm.fit(X_train, Y_train)\n",
        "\n",
        "  # Make predictions and compute the error rate\n",
        "  Y_pred = clf_svm.predict(X_test)\n",
        "  error = zero_one_loss(Y_test, Y_pred)\n",
        "\n",
        "  # Store the error rate for this fold\n",
        "  Error_rate['svm'].append(error)\n",
        "  #####################################################################"
      ],
      "metadata": {
        "id": "f05pO2Jygqfy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold_id in range(num_folds):\n",
        "  X_train = X[kfold_indices[f\"fold_{fold_id}\"]['train']]\n",
        "  Y_train = Y[kfold_indices[f\"fold_{fold_id}\"]['train']]\n",
        "  X_test = X[kfold_indices[f\"fold_{fold_id}\"]['test']]\n",
        "  Y_test = Y[kfold_indices[f\"fold_{fold_id}\"]['test']]\n",
        "\n",
        "  # Decision tree\n",
        "  ######################## TODO #####################################\n",
        "  pipe_tree = Pipeline([\n",
        "    ('classifier', DecisionTreeClassifier(random_state=0))  # Step 1: Decision Tree\n",
        "  ])\n",
        "  clf_tree = GridSearchCV(pipe_tree, param_grid_tree, cv=5)\n",
        "  clf_tree.fit(X_train, Y_train)\n",
        "  Y_pred_tree = clf_tree.predict(X_test)\n",
        "  Error_rate['decision_tree'].append(zero_one_loss(Y_test, Y_pred_tree))\n",
        "  #####################################################################"
      ],
      "metadata": {
        "id": "taXqynYRgxSW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Results\n",
        "\n",
        "Here we report the mean and standard deviation of the error rates over 5 folds for each method."
      ],
      "metadata": {
        "id": "tW0uMLYwZ63z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################## TODO #####################################\n",
        "print(f\"The error rate over 5 folds in CV:\")\n",
        "print(f\"Logistic Regression: mean = {np.mean(Error_rate['logreg']):.4f}, std = {np.std(Error_rate['logreg']):.4f}\")\n",
        "print(f\"SVM: mean = {np.mean(Error_rate['svm']):.4f}, std = {np.std(Error_rate['svm']):.4f}\")\n",
        "print(f\"Decision Tree: mean = {np.mean(Error_rate['decision_tree']):.4f}, std = {np.std(Error_rate['decision_tree']):.4f}\")\n",
        "#####################################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uD1iPyJP25T",
        "outputId": "3645be8f-1a18-4503-eef8-697c1a15685b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The error rate over 5 folds in CV:\n",
            "Logistic Regression: mean = 0.0211, std = 0.0131\n",
            "SVM: mean = 0.0211, std = 0.0181\n",
            "Decision Tree: mean = 0.0686, std = 0.0131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV. Conclusion and Discussion\n",
        "### Conclusion\n",
        "Based on the cross-validation results over 5 folds, Logistic Regression performed the best with a mean error rate of 0.0211 and a standard deviation of 0.0131, indicating high predictive accuracy and stability. The SVM model followed closely with a mean error rate of 0.0211 and a standard deviation of 0.0181, demonstrating comparable performance. The Decision Tree, however, had the highest error rate (mean = 0.0686), suggesting it may not be the optimal choice for this dataset.\n",
        "\n",
        "### Discussion\n",
        "The results suggest that linear models like Logistic Regression and SVM are better suited for this dataset. Logistic Regression's low error rate and minimal standard deviation indicate that it effectively separates the classes with a linear decision boundary."
      ],
      "metadata": {
        "id": "srwwVH9TaBm3"
      }
    }
  ]
}